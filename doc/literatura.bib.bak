@misc{chollet2015keras,
  title={Keras},
  author={Chollet, Fran\c{c}ois and others},
  year={2015},
  howpublished={\url{https://keras.io}},
} 


@article{parameters,
  title={Optimal hyperparameters for deep lstm-networks for sequence labeling tasks},
  author={Reimers, Nils and Gurevych, Iryna},
  journal={arXiv preprint arXiv:1707.06799},
  year={2017}
}

 @misc{twitterStats,
    author = "{Salman Aslam}",
    title = "Twitter by the Numbers: Stats, Demographics and Fun Facts",
    year = "2020",
    url = "https://www.omnicoreagency.com/twitter-statistics/",
    note = "[Online; accessed 13-April-2020]"
  }
  
   @misc{anew_code,
    author = "{Doris Zhou}",
    title = "Implementations of various sentiment analysis methods in Python",
    url = "https://github.com/dwzhou/SentimentAnalysis",
    note = "[Online; accessed 13-April-2020]",
    year={2020}
  }

@article{semeval2017task4,
	author="{Sara Rosenthal, Noura Farra, Preslav Nakov}",
	title={SemEval-2017 Task 4: Sentiment Analysis in Twitter},
	year="2017"
}	

@inproceedings{cliche-2017-bb,
    title = "{BB}{\_}twtr at {S}em{E}val-2017 Task 4: Twitter Sentiment Analysis with {CNN}s and {LSTM}s",
    author = "Cliche, Mathieu",
    booktitle = "Proceedings of the 11th International Workshop on Semantic Evaluation ({S}em{E}val-2017)",
    month = aug,
    year = "2017",
    address = "Vancouver, Canada",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/S17-2094",
    doi = "10.18653/v1/S17-2094",
    pages = "573--580",
    abstract = "In this paper we describe our attempt at producing a state-of-the-art Twitter sentiment classifier using Convolutional Neural Networks (CNNs) and Long Short Term Memory (LSTMs) networks. Our system leverages a large amount of unlabeled data to pre-train word embeddings. We then use a subset of the unlabeled data to fine tune the embeddings using distant supervision. The final CNNs and LSTMs are trained on the SemEval-2017 Twitter dataset where the embeddings are fined tuned again. To boost performances we ensemble several CNNs and LSTMs together. Our approach achieved first rank on all of the five English subtasks amongst 40 teams.",
}

@InProceedings{datastories-Semeval,
  author    = {Baziotis, Christos  and  Pelekis, Nikos  and  Doulkeridis, Christos},
  title     = {DataStories at SemEval-2017 Task 4: Deep LSTM with Attention for Message-level and Topic-based Sentiment Analysis},
  booktitle = {Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017)},
  month     = {August},
  year      = {2017},
  address   = {Vancouver, Canada},
  publisher = {Association for Computational Linguistics},
  pages     = {747--754}
}

@inproceedings{2017-takelab,
    title = "{T}ake{L}ab at {S}em{E}val-2017 Task 4: Recent Deaths and the Power of Nostalgia in Sentiment Analysis in Twitter",
    author = "Lozi{\'c}, David  and
      {\v{S}}ari{\'c}, Doria  and
      Toki{\'c}, Ivan  and
      Medi{\'c}, Zoran  and
      {\v{S}}najder, Jan",
    booktitle = "Proceedings of the 11th International Workshop on Semantic Evaluation ({S}em{E}val-2017)",
    month = aug,
    year = "2017",
    address = "Vancouver, Canada",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/S17-2132",
    doi = "10.18653/v1/S17-2132",
    pages = "784--789",
    abstract = "This paper describes the system we submitted to SemEval-2017 Task 4 (Sentiment Analysis in Twitter), specifically subtasks A, B, and D. Our main focus was topic-based message polarity classification on a two-point scale (subtask B). The system we submitted uses a Support Vector Machine classifier with rich set of features, ranging from standard to more creative, task-specific features, including a series of rating-based features as well as features that account for sentimental reminiscence of past topics and deceased famous people. Our system ranked 14th out of 39 submissions in subtask A, 5th out of 24 submissions in subtask B, and 3rd out of 16 submissions in subtask D.",
}

@misc{w2v,
  title={Computing numeric representations of words in a high-dimensional space},
  author={Mikolov, Tomas and Chen, Kai and Corrado, Gregory S and Dean, Jeffrey A},
  year={2015},
  month=may # "~19",
  publisher={Google Patents},
  note={US Patent 9,037,464}
}

@techreport{anew,
  title={Affective norms for English words (ANEW): Instruction manual and affective ratings},
  author={Bradley, Margaret M and Lang, Peter J},
  year={1999},
  institution={Technical report C-1, the center for research in psychophysiology~…}
}

@article{anew2,
  title={Norms of valence, arousal, and dominance for 13,915 English lemmas},
  author={Warriner, Amy Beth and Kuperman, Victor and Brysbaert, Marc},
  journal={Behavior research methods},
  volume={45},
  number={4},
  pages={1191--1207},
  year={2013},
  publisher={Springer}
}

@book{nltk,
  title={Natural language processing with Python: analyzing text with the natural language toolkit},
  author={Bird, Steven and Klein, Ewan and Loper, Edward},
  year={2009},
  publisher={" O'Reilly Media, Inc."}
}

@article{svm,
  title={Support-vector networks},
  author={Cortes, Corinna and Vapnik, Vladimir},
  journal={Machine learning},
  volume={20},
  number={3},
  pages={273--297},
  year={1995},
  publisher={Springer}
}

@book{strojno_skripta,
title={Strojno učenje},
author={Jan Šnajder, Bojana Dalbelo Bašić},
year={2014}
}

@book{cupic,
 title = {Umjetna inteligencija},
 subtitle = {Umjetne neuronske mreže},
 author = {Marko Čupić},
 year = {2016},
 url = {java.zemris.fer.hr/nastava/ui/}
}

@misc{akt,
title={Neural Networks and Deep Learning},
author={Andrew Ng},
url={https://www.coursera.org/lecture/neural-networks-deep-learning/activation-functions-4dDC1}
}

@misc{leksikon,
title={Lexicon},
author={Hu, Liu},
year={2006},
url={https://www.cs.uic.edu/~liub/FBS/sentiment-analysis.html#lexicon}
}

@inproceedings{rnn_training,
  title={On the difficulty of training recurrent neural networks},
  author={Pascanu, Razvan and Mikolov, Tomas and Bengio, Yoshua},
  booktitle={International conference on machine learning},
  pages={1310--1318},
  year={2013}
}

@article{kingma2014adam,
  title={Adam: A method for stochastic optimization},
  author={Kingma, Diederik P and Ba, Jimmy},
  journal={arXiv preprint arXiv:1412.6980},
  year={2014}
}

@misc{tensorflow2015-whitepaper,
title={ {TensorFlow}: Large-Scale Machine Learning on Heterogeneous Systems},
url={https://www.tensorflow.org/},
note={Software available from tensorflow.org},
author={
    Mart\'{\i}n~Abadi and
    Ashish~Agarwal and
    Paul~Barham and
    Eugene~Brevdo and
    Zhifeng~Chen and
    Craig~Citro and
    Greg~S.~Corrado and
    Andy~Davis and
    Jeffrey~Dean and
    Matthieu~Devin and
    Sanjay~Ghemawat and
    Ian~Goodfellow and
    Andrew~Harp and
    Geoffrey~Irving and
    Michael~Isard and
    Yangqing Jia and
    Rafal~Jozefowicz and
    Lukasz~Kaiser and
    Manjunath~Kudlur and
    Josh~Levenberg and
    Dandelion~Man\'{e} and
    Rajat~Monga and
    Sherry~Moore and
    Derek~Murray and
    Chris~Olah and
    Mike~Schuster and
    Jonathon~Shlens and
    Benoit~Steiner and
    Ilya~Sutskever and
    Kunal~Talwar and
    Paul~Tucker and
    Vincent~Vanhoucke and
    Vijay~Vasudevan and
    Fernanda~Vi\'{e}gas and
    Oriol~Vinyals and
    Pete~Warden and
    Martin~Wattenberg and
    Martin~Wicke and
    Yuan~Yu and
    Xiaoqiang~Zheng},
  year={2015},
}

@article{losirez,
author = {Zimbra, David and Abbasi, Ahmed and Zeng, Daniel},
year = {2018},
month = {05},
pages = {},
title = {The State-of-the-Art in Twitter Sentiment Analysis: A Review and Benchmark Evaluation},
volume = {xx, No. x},
journal = {ACM Transactions on Management Information Systems},
doi = {10.1145/3185045}
}

@misc{al-masri_2019, title={What Are Overfitting and Underfitting in Machine Learning?}, url={https://towardsdatascience.com/what-are-overfitting-and-underfitting-in-machine-learning-a96b30864690}, journal={Medium}, publisher={Towards Data Science}, author={Al-Masri, Anas}, year={2019}, month={Jun}}